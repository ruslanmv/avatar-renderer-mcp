{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé¨ Avatar Renderer MCP - Google Colab Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruslanmv/avatar-renderer-mcp/blob/main/demo_colab.ipynb)\n",
    "\n",
    "**Transform static images into dynamic AI-powered avatars with realistic expressions and voice synchronization**\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. ‚úÖ Set up Avatar Renderer MCP in Google Colab\n",
    "2. ‚úÖ Install and verify the MCP server\n",
    "3. ‚úÖ Generate \"Hello World\" talking avatars\n",
    "4. ‚úÖ Create professional demo videos\n",
    "5. ‚úÖ Use both quality modes (real-time & high-quality)\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö° Colab Pro Recommended**: For faster processing and GPU access\n",
    "\n",
    "**üåê Website:** [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "\n",
    "**üì¶ Repository:** [https://github.com/ruslanmv/avatar-renderer-mcp](https://github.com/ruslanmv/avatar-renderer-mcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-warning",
   "metadata": {
    "id": "colab-warning"
   },
   "source": [
    "## ‚ö†Ô∏è Important Notes\n",
    "\n",
    "### Runtime Requirements\n",
    "- **Runtime Type**: Python 3\n",
    "- **Hardware**: GPU recommended (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "- **RAM**: High-RAM runtime recommended for high-quality mode\n",
    "- **Disk Space**: ~10 GB for models and dependencies\n",
    "\n",
    "### Expected Processing Times\n",
    "- **Real-time mode**: 30-60 seconds (CPU) / 10-20 seconds (GPU)\n",
    "- **High-quality mode**: 2-5 minutes (GPU required)\n",
    "\n",
    "### Colab Limitations\n",
    "- Session timeout after 12 hours (or 90 minutes idle)\n",
    "- Models must be re-downloaded each session (or use Google Drive)\n",
    "- GPU availability not guaranteed on free tier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1-env",
   "metadata": {
    "id": "section-1-env"
   },
   "source": [
    "## 1Ô∏è‚É£ Environment Setup & System Dependencies\n",
    "\n",
    "First, let's check the Colab environment and install system dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-env",
   "metadata": {
    "id": "check-env"
   },
   "outputs": [],
   "source": [
    "# Check Colab environment\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç Environment Information\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Working Directory: {os.getcwd()}\")\n",
    "print(f\"Platform: {sys.platform}\")\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚ö†Ô∏è  Not running in Colab (some features may not work)\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"\\nGPU Available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(\"‚úÖ GPU acceleration enabled\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Processing will be slower.\")\n",
    "    print(\"üí° Tip: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-system",
   "metadata": {
    "id": "install-system"
   },
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "print(\"üì¶ Installing system dependencies...\\n\")\n",
    "\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq ffmpeg libsm6 libxext6 libxrender-dev libgomp1 > /dev/null 2>&1\n",
    "\n",
    "# Verify FFmpeg installation\n",
    "!ffmpeg -version | head -3\n",
    "\n",
    "print(\"\\n‚úÖ System dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2-clone",
   "metadata": {
    "id": "section-2-clone"
   },
   "source": [
    "## 2Ô∏è‚É£ Clone Repository & Install Dependencies\n",
    "\n",
    "Clone the Avatar Renderer MCP repository and install Python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone-repo",
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path(\"/content/avatar-renderer-mcp\")\n",
    "\n",
    "if REPO_DIR.exists():\n",
    "    print(\"üìÇ Repository already cloned, pulling latest changes...\")\n",
    "    !cd {REPO_DIR} && git pull\n",
    "else:\n",
    "    print(\"üì• Cloning Avatar Renderer MCP repository...\")\n",
    "    !git clone https://github.com/ruslanmv/avatar-renderer-mcp.git {REPO_DIR}\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"\\n‚úÖ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-python-deps",
   "metadata": {
    "id": "install-python-deps"
   },
   "outputs": [],
   "source": [
    "# Install Python dependencies\n",
    "print(\"üì¶ Installing Python dependencies...\")\n",
    "print(\"This may take 3-5 minutes...\\n\")\n",
    "\n",
    "# Install the package in editable mode\n",
    "!pip install -q -e .\n",
    "\n",
    "# Install additional dependencies\n",
    "!pip install -q ipython pillow matplotlib\n",
    "\n",
    "print(\"\\n‚úÖ Python dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-external",
   "metadata": {
    "id": "section-3-external"
   },
   "source": [
    "## 3Ô∏è‚É£ Install External Dependencies (SadTalker, Wav2Lip, etc.)\n",
    "\n",
    "Install the external Git repositories needed for avatar generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-external",
   "metadata": {
    "id": "install-external"
   },
   "outputs": [],
   "source": [
    "# Create external dependencies directory\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "EXT_DEPS_DIR = REPO_DIR / \"external_deps\"\n",
    "EXT_DEPS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"üì¶ Installing external dependencies...\\n\")\n",
    "\n",
    "# Install SadTalker\n",
    "sadtalker_dir = EXT_DEPS_DIR / \"SadTalker\"\n",
    "if not sadtalker_dir.exists():\n",
    "    print(\"üì• Cloning SadTalker...\")\n",
    "    !git clone --depth=1 https://github.com/OpenTalker/SadTalker.git {sadtalker_dir}\n",
    "    !pip install -q -r {sadtalker_dir}/requirements.txt\n",
    "else:\n",
    "    print(\"‚úì SadTalker already installed\")\n",
    "\n",
    "# Install First Order Motion Model (FOMM)\n",
    "fomm_dir = EXT_DEPS_DIR / \"first-order-model\"\n",
    "if not fomm_dir.exists():\n",
    "    print(\"üì• Cloning First Order Motion Model...\")\n",
    "    !git clone --depth=1 https://github.com/AliaksandrSiarohin/first-order-model.git {fomm_dir}\n",
    "else:\n",
    "    print(\"‚úì FOMM already installed\")\n",
    "\n",
    "# Install Wav2Lip\n",
    "wav2lip_dir = EXT_DEPS_DIR / \"Wav2Lip\"\n",
    "if not wav2lip_dir.exists():\n",
    "    print(\"üì• Cloning Wav2Lip...\")\n",
    "    !git clone --depth=1 https://github.com/Rudrabha/Wav2Lip.git {wav2lip_dir}\n",
    "    !pip install -q -r {wav2lip_dir}/requirements.txt\n",
    "else:\n",
    "    print(\"‚úì Wav2Lip already installed\")\n",
    "\n",
    "# Add to Python path\n",
    "if str(EXT_DEPS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(EXT_DEPS_DIR))\n",
    "    print(f\"\\n‚úÖ Added to Python path: {EXT_DEPS_DIR}\")\n",
    "\n",
    "print(\"\\n‚úÖ External dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-models",
   "metadata": {
    "id": "section-4-models"
   },
   "source": [
    "## 4Ô∏è‚É£ Download Model Checkpoints\n",
    "\n",
    "Download the pre-trained model weights. This is the largest download (~3-5 GB).\n",
    "\n",
    "**Note**: Models will be downloaded to Colab's temporary storage and need to be re-downloaded each session unless you mount Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-models-dir",
   "metadata": {
    "id": "setup-models-dir"
   },
   "outputs": [],
   "source": [
    "# Option 1: Use temporary Colab storage (faster but lost after session)\n",
    "MODELS_DIR = Path(\"/content/models\")\n",
    "\n",
    "# Option 2: Use Google Drive (persistent but slower)\n",
    "# Uncomment the following lines to use Google Drive:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# MODELS_DIR = Path(\"/content/drive/MyDrive/avatar-renderer-models\")\n",
    "\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "os.environ['MODEL_ROOT'] = str(MODELS_DIR)\n",
    "\n",
    "print(f\"üìÅ Models directory: {MODELS_DIR}\")\n",
    "print(f\"Storage: {'Google Drive (persistent)' if 'drive' in str(MODELS_DIR) else 'Colab storage (temporary)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-models",
   "metadata": {
    "id": "download-models"
   },
   "outputs": [],
   "source": [
    "# Download model checkpoints\n",
    "import urllib.request\n",
    "import gdown\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üì• Downloading model checkpoints...\")\n",
    "print(\"This will take 5-10 minutes depending on your connection...\\n\")\n",
    "\n",
    "def download_file(url, output_path, description=\"\"):\n",
    "    \"\"\"Download a file with progress bar\"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    if output_path.exists():\n",
    "        print(f\"‚úì {description} already exists, skipping...\")\n",
    "        return True\n",
    "    \n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"üì• Downloading {description}...\")\n",
    "    \n",
    "    try:\n",
    "        if 'drive.google.com' in url:\n",
    "            gdown.download(url, str(output_path), quiet=False, fuzzy=True)\n",
    "        else:\n",
    "            urllib.request.urlretrieve(url, output_path)\n",
    "        print(f\"‚úÖ {description} downloaded\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to download {description}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Install gdown for Google Drive downloads\n",
    "!pip install -q gdown\n",
    "\n",
    "# Model URLs (these are examples - update with actual model URLs)\n",
    "models_config = [\n",
    "    {\n",
    "        'name': 'SadTalker Checkpoint',\n",
    "        'url': 'https://github.com/OpenTalker/SadTalker/releases/download/v0.0.1/checkpoints.zip',\n",
    "        'path': MODELS_DIR / 'sadtalker' / 'checkpoints.zip',\n",
    "        'extract': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wav2Lip GAN',\n",
    "        'url': 'https://github.com/Rudrabha/Wav2Lip/releases/download/v1.0/wav2lip_gan.pth',\n",
    "        'path': MODELS_DIR / 'wav2lip' / 'wav2lip_gan.pth',\n",
    "        'extract': False\n",
    "    },\n",
    "    {\n",
    "        'name': 'GFPGAN v1.3',\n",
    "        'url': 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth',\n",
    "        'path': MODELS_DIR / 'gfpgan' / 'GFPGANv1.3.pth',\n",
    "        'extract': False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Download models\n",
    "success_count = 0\n",
    "for model in models_config:\n",
    "    if download_file(model['url'], model['path'], model['name']):\n",
    "        success_count += 1\n",
    "        \n",
    "        # Extract if needed\n",
    "        if model.get('extract') and model['path'].suffix == '.zip':\n",
    "            print(f\"üì¶ Extracting {model['name']}...\")\n",
    "            !unzip -q {model['path']} -d {model['path'].parent}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Downloaded {success_count}/{len(models_config)} models\")\n",
    "if success_count < len(models_config):\n",
    "    print(\"‚ö†Ô∏è  Some models failed to download. You may experience limited functionality.\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-verify",
   "metadata": {
    "id": "section-5-verify"
   },
   "source": [
    "## 5Ô∏è‚É£ Verify Installation & Test Imports\n",
    "\n",
    "Let's verify that all components are installed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-installation",
   "metadata": {
    "id": "verify-installation"
   },
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç Verifying installation...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check Python version\n",
    "py_version = sys.version_info\n",
    "print(f\"Python Version: {py_version.major}.{py_version.minor}.{py_version.micro}\")\n",
    "if py_version >= (3, 11):\n",
    "    print(\"‚úÖ Python version compatible\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Python 3.11+ recommended\")\n",
    "\n",
    "# Check imports\n",
    "print(\"\\nüì¶ Checking dependencies...\")\n",
    "\n",
    "imports_to_check = [\n",
    "    ('torch', 'PyTorch'),\n",
    "    ('torchvision', 'TorchVision'),\n",
    "    ('fastapi', 'FastAPI'),\n",
    "    ('librosa', 'Librosa'),\n",
    "    ('soundfile', 'SoundFile'),\n",
    "    ('gfpgan', 'GFPGAN'),\n",
    "    ('diffusers', 'Diffusers'),\n",
    "    ('transformers', 'Transformers'),\n",
    "]\n",
    "\n",
    "failed_imports = []\n",
    "for module_name, display_name in imports_to_check:\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        print(f\"  ‚úÖ {display_name}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"  ‚ùå {display_name} - {e}\")\n",
    "        failed_imports.append(display_name)\n",
    "\n",
    "# Check app module\n",
    "print(\"\\nüì¶ Checking app modules...\")\n",
    "try:\n",
    "    from app.pipeline import render_pipeline\n",
    "    print(\"  ‚úÖ app.pipeline\")\n",
    "except ImportError as e:\n",
    "    print(f\"  ‚ùå app.pipeline - {e}\")\n",
    "    failed_imports.append('app.pipeline')\n",
    "\n",
    "try:\n",
    "    from app.settings import settings\n",
    "    print(\"  ‚úÖ app.settings\")\n",
    "except ImportError as e:\n",
    "    print(f\"  ‚ùå app.settings - {e}\")\n",
    "\n",
    "# Check directories\n",
    "print(\"\\nüìÅ Checking directories...\")\n",
    "dirs_to_check = [\n",
    "    (REPO_DIR, \"Repository\"),\n",
    "    (EXT_DEPS_DIR, \"External dependencies\"),\n",
    "    (MODELS_DIR, \"Models\"),\n",
    "]\n",
    "\n",
    "for dir_path, name in dirs_to_check:\n",
    "    if dir_path.exists():\n",
    "        print(f\"  ‚úÖ {name}: {dir_path}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {name} not found: {dir_path}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if not failed_imports:\n",
    "    print(\"‚úÖ All components verified successfully!\")\n",
    "    print(\"üéâ Ready to generate avatars!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  {len(failed_imports)} components failed to load:\")\n",
    "    for name in failed_imports:\n",
    "        print(f\"  - {name}\")\n",
    "    print(\"\\nüí° Try re-running the installation cells above\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6-mcp",
   "metadata": {
    "id": "section-6-mcp"
   },
   "source": [
    "## 6Ô∏è‚É£ Setup & Test MCP Server\n",
    "\n",
    "Now let's set up the MCP (Model Context Protocol) server and verify it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-mcp",
   "metadata": {
    "id": "setup-mcp"
   },
   "outputs": [],
   "source": [
    "# Setup environment variables for MCP server\n",
    "import os\n",
    "\n",
    "print(\"‚öôÔ∏è Configuring MCP server...\\n\")\n",
    "\n",
    "# Set environment variables\n",
    "env_vars = {\n",
    "    'MODEL_ROOT': str(MODELS_DIR),\n",
    "    'PYTHONPATH': f\"{REPO_DIR}:{EXT_DEPS_DIR}:{os.environ.get('PYTHONPATH', '')}\",\n",
    "    'LOG_LEVEL': 'INFO',\n",
    "    'TMP_DIR': '/tmp',\n",
    "    'CUDA_VISIBLE_DEVICES': '0' if torch.cuda.is_available() else '',\n",
    "}\n",
    "\n",
    "for key, value in env_vars.items():\n",
    "    os.environ[key] = value\n",
    "    print(f\"‚úì {key}={value[:50]}{'...' if len(value) > 50 else ''}\")\n",
    "\n",
    "print(\"\\n‚úÖ MCP server configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-mcp-imports",
   "metadata": {
    "id": "test-mcp-imports"
   },
   "outputs": [],
   "source": [
    "# Test MCP server components\n",
    "print(\"üß™ Testing MCP server components...\\n\")\n",
    "\n",
    "try:\n",
    "    # Test pipeline import\n",
    "    from app.pipeline import render_pipeline\n",
    "    print(\"‚úÖ Pipeline module loaded\")\n",
    "    \n",
    "    # Test settings\n",
    "    from app.settings import settings\n",
    "    print(\"‚úÖ Settings module loaded\")\n",
    "    print(f\"   Model root: {settings.model_root if hasattr(settings, 'model_root') else 'Not set'}\")\n",
    "    \n",
    "    # Test API (optional)\n",
    "    try:\n",
    "        from app.api import app\n",
    "        print(\"‚úÖ API module loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  API module: {e}\")\n",
    "    \n",
    "    # Test MCP server\n",
    "    try:\n",
    "        from app.mcp_server import render_avatar_tool\n",
    "        print(\"‚úÖ MCP server module loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  MCP server: {e}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ MCP server components verified!\")\n",
    "    print(\"üé¨ Ready to generate avatars!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading MCP components: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Make sure all installation cells completed successfully\")\n",
    "    print(\"2. Check that models are downloaded\")\n",
    "    print(\"3. Verify Python path includes external dependencies\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7-hello",
   "metadata": {
    "id": "section-7-hello"
   },
   "source": [
    "## 7Ô∏è‚É£ Generate Your First Avatar - \"Hello World\"\n",
    "\n",
    "Let's create a simple \"Hello World\" talking avatar using the test assets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-output",
   "metadata": {
    "id": "setup-output"
   },
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "OUTPUT_DIR = Path(\"/content/avatar_outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Check for test assets\n",
    "test_image = REPO_DIR / \"tests/assets/alice.png\"\n",
    "test_audio = REPO_DIR / \"tests/assets/hello.wav\"\n",
    "\n",
    "print(\"\\nüé® Test assets:\")\n",
    "if test_image.exists():\n",
    "    print(f\"  ‚úÖ Image: {test_image}\")\n",
    "    # Display the test image\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=str(test_image), width=300))\n",
    "else:\n",
    "    print(f\"  ‚ùå Image not found: {test_image}\")\n",
    "\n",
    "if test_audio.exists():\n",
    "    print(f\"  ‚úÖ Audio: {test_audio}\")\n",
    "    # Play the test audio\n",
    "    from IPython.display import Audio, display\n",
    "    display(Audio(filename=str(test_audio)))\n",
    "else:\n",
    "    print(f\"  ‚ùå Audio not found: {test_audio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-hello-world",
   "metadata": {
    "id": "generate-hello-world"
   },
   "outputs": [],
   "source": [
    "# Generate Hello World avatar\n",
    "import time\n",
    "from IPython.display import Video, display\n",
    "\n",
    "output_video = OUTPUT_DIR / \"hello_world.mp4\"\n",
    "\n",
    "print(\"üé¨ Generating 'Hello World' Avatar\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input Image: {test_image.name}\")\n",
    "print(f\"Input Audio: {test_audio.name}\")\n",
    "print(f\"Output: {output_video.name}\")\n",
    "print(f\"Quality Mode: auto\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚è≥ Processing... This may take 30-60 seconds...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Import and run the pipeline\n",
    "    from app.pipeline import render_pipeline\n",
    "    \n",
    "    result = render_pipeline(\n",
    "        face_image=str(test_image),\n",
    "        audio=str(test_audio),\n",
    "        out_path=str(output_video),\n",
    "        quality_mode=\"auto\"  # Auto-select best mode\n",
    "    )\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚úÖ SUCCESS! Avatar generated!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"‚è±Ô∏è  Processing time: {processing_time:.2f} seconds\")\n",
    "    print(f\"üìÅ Output file: {result}\")\n",
    "    print(f\"üìä File size: {Path(result).stat().st_size / (1024*1024):.2f} MB\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Display the video\n",
    "    print(\"üé• Your AI Avatar:\")\n",
    "    display(Video(result, width=640, embed=True))\n",
    "    \n",
    "except Exception as e:\n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚ùå ERROR: Avatar generation failed\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(f\"Time elapsed: {processing_time:.2f} seconds\")\n",
    "    print(f\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Check that models are downloaded correctly\")\n",
    "    print(\"2. Verify test assets exist\")\n",
    "    print(\"3. Check GPU availability for high-quality mode\")\n",
    "    print(\"4. Try quality_mode='real_time' for CPU-only systems\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Print full traceback for debugging\n",
    "    import traceback\n",
    "    print(\"\\nüìã Full error trace:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8-quality",
   "metadata": {
    "id": "section-8-quality"
   },
   "source": [
    "## 8Ô∏è‚É£ Test Different Quality Modes\n",
    "\n",
    "Let's compare the two quality modes:\n",
    "\n",
    "| Feature | Real-Time | High-Quality |\n",
    "|---------|-----------|-------------|\n",
    "| **Speed** | <3s (local) / 30-60s (Colab) | 2-5 minutes |\n",
    "| **GPU Required** | No | Yes |\n",
    "| **Pipeline** | SadTalker + Wav2Lip | FOMM + Diff2Lip + GFPGAN |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-realtime",
   "metadata": {
    "id": "test-realtime"
   },
   "outputs": [],
   "source": [
    "# Test Real-Time Mode (CPU-friendly)\n",
    "import time\n",
    "from IPython.display import Video, display\n",
    "\n",
    "output_realtime = OUTPUT_DIR / \"realtime_demo.mp4\"\n",
    "\n",
    "print(\"‚ö° Testing REAL-TIME Mode\")\n",
    "print(\"=\"*60)\n",
    "print(\"Optimized for speed, works on CPU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    result = render_pipeline(\n",
    "        face_image=str(test_image),\n",
    "        audio=str(test_audio),\n",
    "        out_path=str(output_realtime),\n",
    "        quality_mode=\"real_time\"\n",
    "    )\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ Real-time mode completed in {processing_time:.2f}s\")\n",
    "    display(Video(result, width=640, embed=True))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Real-time mode failed: {e}\")\n",
    "    print(\"This mode requires SadTalker and Wav2Lip models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-highquality",
   "metadata": {
    "id": "test-highquality"
   },
   "outputs": [],
   "source": [
    "# Test High-Quality Mode (GPU required)\n",
    "import time\n",
    "from IPython.display import Video, display\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"‚ö†Ô∏è  High-quality mode requires GPU\")\n",
    "    print(\"üí° Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    print(\"Skipping high-quality test...\")\n",
    "else:\n",
    "    output_hq = OUTPUT_DIR / \"highquality_demo.mp4\"\n",
    "    \n",
    "    print(\"üé® Testing HIGH-QUALITY Mode\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Best quality with GFPGAN enhancement\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        result = render_pipeline(\n",
    "            face_image=str(test_image),\n",
    "            audio=str(test_audio),\n",
    "            out_path=str(output_hq),\n",
    "            quality_mode=\"high_quality\"\n",
    "        )\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"\\n‚úÖ High-quality mode completed in {processing_time:.2f}s\")\n",
    "        display(Video(result, width=640, embed=True))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå High-quality mode failed: {e}\")\n",
    "        print(\"This mode requires FOMM, Diff2Lip, and GFPGAN models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9-custom",
   "metadata": {
    "id": "section-9-custom"
   },
   "source": [
    "## 9Ô∏è‚É£ Create Custom Avatars\n",
    "\n",
    "Upload your own images and audio files to create custom avatars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-files",
   "metadata": {
    "id": "upload-files"
   },
   "outputs": [],
   "source": [
    "# Upload custom files\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "UPLOAD_DIR = Path(\"/content/uploads\")\n",
    "UPLOAD_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"üì§ Upload your files:\")\n",
    "print(\"1. Click the 'Choose Files' button below\")\n",
    "print(\"2. Select an image (PNG/JPG) and audio file (WAV/MP3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded files\n",
    "uploaded_files = []\n",
    "for filename in uploaded.keys():\n",
    "    src = Path(filename)\n",
    "    dst = UPLOAD_DIR / filename\n",
    "    shutil.move(str(src), str(dst))\n",
    "    uploaded_files.append(dst)\n",
    "    print(f\"‚úÖ Uploaded: {filename}\")\n",
    "\n",
    "print(f\"\\nüìÅ Files saved to: {UPLOAD_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-custom",
   "metadata": {
    "id": "generate-custom"
   },
   "outputs": [],
   "source": [
    "# Generate avatar from uploaded files\n",
    "from IPython.display import Video, display\n",
    "import time\n",
    "\n",
    "# Find uploaded image and audio\n",
    "image_files = list(UPLOAD_DIR.glob(\"*.png\")) + list(UPLOAD_DIR.glob(\"*.jpg\"))\n",
    "audio_files = list(UPLOAD_DIR.glob(\"*.wav\")) + list(UPLOAD_DIR.glob(\"*.mp3\"))\n",
    "\n",
    "if not image_files or not audio_files:\n",
    "    print(\"‚ö†Ô∏è  Please upload both an image and an audio file\")\n",
    "else:\n",
    "    custom_image = image_files[0]\n",
    "    custom_audio = audio_files[0]\n",
    "    custom_output = OUTPUT_DIR / \"custom_avatar.mp4\"\n",
    "    \n",
    "    print(\"üé¨ Generating custom avatar...\")\n",
    "    print(f\"  Image: {custom_image.name}\")\n",
    "    print(f\"  Audio: {custom_audio.name}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        result = render_pipeline(\n",
    "            face_image=str(custom_image),\n",
    "            audio=str(custom_audio),\n",
    "            out_path=str(custom_output),\n",
    "            quality_mode=\"auto\"\n",
    "        )\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"\\n‚úÖ Custom avatar generated in {processing_time:.2f}s\")\n",
    "        display(Video(result, width=640, embed=True))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-10-download",
   "metadata": {
    "id": "section-10-download"
   },
   "source": [
    "## üîü Download Your Videos\n",
    "\n",
    "Download the generated videos to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-videos",
   "metadata": {
    "id": "download-videos"
   },
   "outputs": [],
   "source": [
    "# Download generated videos\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Available videos for download:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "video_files = list(OUTPUT_DIR.glob(\"*.mp4\"))\n",
    "\n",
    "if not video_files:\n",
    "    print(\"No videos found. Generate some avatars first!\")\n",
    "else:\n",
    "    for video in video_files:\n",
    "        size_mb = video.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  üìπ {video.name} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    print(\"\\nüíæ Click below to download each video:\")\n",
    "    for video in video_files:\n",
    "        print(f\"\\nDownloading: {video.name}\")\n",
    "        files.download(str(video))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-11-tips",
   "metadata": {
    "id": "section-11-tips"
   },
   "source": [
    "## üí° Tips & Best Practices\n",
    "\n",
    "### üñºÔ∏è Image Requirements\n",
    "- **Format**: PNG or JPG\n",
    "- **Face**: Clear, front-facing portrait\n",
    "- **Resolution**: Minimum 512x512, recommended 1024x1024\n",
    "- **Lighting**: Well-lit, avoid harsh shadows\n",
    "\n",
    "### üé§ Audio Requirements\n",
    "- **Format**: WAV or MP3\n",
    "- **Sample Rate**: 16kHz recommended\n",
    "- **Quality**: Clear speech, minimal background noise\n",
    "- **Length**: Keep it concise (10-30 seconds optimal)\n",
    "\n",
    "### ‚ö° Performance Tips\n",
    "1. **Use GPU**: Enable GPU runtime for 10x faster processing\n",
    "2. **Real-time mode**: Use for faster processing on CPU\n",
    "3. **High-quality mode**: Use GPU runtime for best results\n",
    "4. **Google Drive**: Mount Drive to persist models across sessions\n",
    "5. **Colab Pro**: Consider upgrading for longer sessions and better GPUs\n",
    "\n",
    "### üîß Troubleshooting\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| Out of memory | Use real_time mode or restart runtime |\n",
    "| Slow processing | Enable GPU runtime |\n",
    "| Models not found | Re-run model download cells |\n",
    "| Import errors | Re-run installation cells |\n",
    "| Session timeout | Mount Google Drive to save models |\n",
    "\n",
    "### üìö Additional Resources\n",
    "- **Documentation**: [README.md](https://github.com/ruslanmv/avatar-renderer-mcp)\n",
    "- **Website**: [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "- **Issues**: [GitHub Issues](https://github.com/ruslanmv/avatar-renderer-mcp/issues)\n",
    "- **Author**: [Ruslan Magana Vsevolodovna](https://ruslanmv.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-12-api",
   "metadata": {
    "id": "section-12-api"
   },
   "source": [
    "## üîå MCP Server API Reference\n",
    "\n",
    "### Core Function\n",
    "\n",
    "```python\n",
    "render_pipeline(\n",
    "    face_image: str,              # Path to avatar image\n",
    "    audio: str,                   # Path to audio file\n",
    "    out_path: str,                # Output video path\n",
    "    reference_video: str = None,  # Optional driving video\n",
    "    quality_mode: str = \"auto\"    # \"real_time\", \"high_quality\", \"auto\"\n",
    ") -> str  # Returns path to generated video\n",
    "```\n",
    "\n",
    "### Quality Modes\n",
    "\n",
    "#### `real_time`\n",
    "- Fast processing, CPU-friendly\n",
    "- Pipeline: SadTalker + Wav2Lip\n",
    "- Best for: Live streaming, chatbots\n",
    "\n",
    "#### `high_quality`\n",
    "- Maximum quality with GFPGAN\n",
    "- Pipeline: FOMM + Diff2Lip + GFPGAN\n",
    "- Best for: Marketing videos, YouTube\n",
    "\n",
    "#### `auto` (default)\n",
    "- Automatically selects best mode\n",
    "- Based on GPU and model availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully set up Avatar Renderer MCP in Google Colab and generated your first AI-powered talking avatar!\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Create more avatars** with your own images and audio\n",
    "2. **Experiment with quality modes** to find the best balance\n",
    "3. **Deploy to production** using the Docker/Kubernetes guides\n",
    "4. **Integrate with your app** using the REST API or MCP protocol\n",
    "\n",
    "### Support & Contact\n",
    "\n",
    "- üåê **Website**: [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "- üì¶ **Repository**: [https://github.com/ruslanmv/avatar-renderer-mcp](https://github.com/ruslanmv/avatar-renderer-mcp)\n",
    "- üìß **Email**: contact@ruslanmv.com\n",
    "- üë§ **Author**: [Ruslan Magana Vsevolodovna](https://ruslanmv.com)\n",
    "\n",
    "---\n",
    "\n",
    "*Transform static images into dynamic, AI-powered avatars with realistic expressions and voice synchronization* üé¨‚ú®"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
