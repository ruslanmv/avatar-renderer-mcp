{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé¨ Avatar Renderer MCP - Google Colab Demo (Fixed)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruslanmv/avatar-renderer-mcp/blob/main/demo_colab.ipynb)\n",
    "\n",
    "**Transform static images into dynamic AI-powered avatars with realistic expressions and voice synchronization**\n",
    "\n",
    "üîß **This notebook includes all critical fixes for Colab compatibility**\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö° GPU Recommended**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4)\n",
    "\n",
    "**üåê Website:** [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1-env",
   "metadata": {
    "id": "section-1-env"
   },
   "source": [
    "## 1Ô∏è‚É£ Environment Check & System Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-env",
   "metadata": {
    "id": "check-env"
   },
   "outputs": [],
   "source": [
    "# Check environment\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç Environment Information\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "py_version = sys.version_info\n",
    "if py_version < (3, 10):\n",
    "    print(\"‚ùå ERROR: Python 3.10+ required\")\n",
    "    raise RuntimeError(\"Python 3.10+ required. Please use a compatible runtime.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Python {py_version.major}.{py_version.minor} compatible\")\n",
    "\n",
    "# Check Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚ö†Ô∏è  Not in Colab\")\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"\\nGPU Available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU. Processing will be slower.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-system",
   "metadata": {
    "id": "install-system"
   },
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "print(\"üì¶ Installing system dependencies...\\n\")\n",
    "!apt-get update -qq && apt-get install -y -qq ffmpeg libsm6 libxext6 libxrender-dev libgomp1 git git-lfs > /dev/null 2>&1\n",
    "!ffmpeg -version | head -3\n",
    "print(\"\\n‚úÖ System dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2-clone",
   "metadata": {
    "id": "section-2-clone"
   },
   "source": [
    "## 2Ô∏è‚É£ Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone-repo",
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "REPO_DIR = Path(\"/content/avatar-renderer-mcp\")\n",
    "\n",
    "if REPO_DIR.exists():\n",
    "    print(\"üìÇ Repository exists, pulling latest...\")\n",
    "    !cd {REPO_DIR} && git pull -q\n",
    "else:\n",
    "    print(\"üì• Cloning repository...\")\n",
    "    !git clone -q https://github.com/ruslanmv/avatar-renderer-mcp.git {REPO_DIR}\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"‚úÖ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-python",
   "metadata": {
    "id": "section-3-python"
   },
   "source": [
    "## 3Ô∏è‚É£ Install Python Dependencies\n",
    "\n",
    "**CRITICAL FIX**: We install without forcing torch reinstall to preserve Colab's optimized GPU-enabled torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-python",
   "metadata": {
    "id": "install-python"
   },
   "outputs": [],
   "source": "# Install Python dependencies (FIX: use --no-deps for core package to avoid torch conflicts)\nprint(\"üì¶ Installing Python dependencies...\")\nprint(\"This preserves Colab's optimized torch installation.\\n\")\n\n# Install the package structure without dependencies first\n!pip install -q --no-deps -e .\n\n# Then install only the safe dependencies (avoiding torch/torchvision reinstall)\n!pip install -q fastapi uvicorn python-multipart pydantic pydantic-settings python-dotenv\n!pip install -q diffusers transformers huggingface-hub safetensors accelerate\n!pip install -q gfpgan librosa soundfile\n!pip install -q gdown opencv-python imageio moviepy\n!pip install -q requests click rich\n!pip install -q ffmpeg-python pandas  # CRITICAL FIX: Required by first-order-model\n\nprint(\"\\n‚úÖ Python dependencies installed!\")\nimport torch  # Import torch to verify version\nprint(f\"‚úÖ Torch version: {torch.__version__} (Colab's version preserved)\")"
  },
  {
   "cell_type": "markdown",
   "id": "section-4-external",
   "metadata": {
    "id": "section-4-external"
   },
   "source": [
    "## 4Ô∏è‚É£ Install External Dependencies\n",
    "\n",
    "**CRITICAL FIX**: We clone repos but DON'T install their requirements.txt (which would break torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-external",
   "metadata": {
    "id": "install-external"
   },
   "outputs": [],
   "source": [
    "# Setup external dependencies directory\n",
    "EXT_DEPS_DIR = REPO_DIR / \"external_deps\"\n",
    "EXT_DEPS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"üì¶ Installing external dependencies...\\n\")\n",
    "\n",
    "# SadTalker\n",
    "sadtalker_dir = EXT_DEPS_DIR / \"SadTalker\"\n",
    "if not sadtalker_dir.exists():\n",
    "    print(\"üì• Cloning SadTalker...\")\n",
    "    !git clone -q --depth=1 https://github.com/OpenTalker/SadTalker.git {sadtalker_dir}\n",
    "    # FIX: Don't install requirements.txt - install only safe deps\n",
    "    !pip install -q yacs pyyaml\n",
    "else:\n",
    "    print(\"‚úì SadTalker already installed\")\n",
    "\n",
    "# First Order Motion Model\n",
    "fomm_dir = EXT_DEPS_DIR / \"first-order-model\"\n",
    "if not fomm_dir.exists():\n",
    "    print(\"üì• Cloning First Order Motion Model...\")\n",
    "    !git clone -q --depth=1 https://github.com/AliaksandrSiarohin/first-order-model.git {fomm_dir}\n",
    "else:\n",
    "    print(\"‚úì FOMM already installed\")\n",
    "\n",
    "# Wav2Lip\n",
    "wav2lip_dir = EXT_DEPS_DIR / \"Wav2Lip\"\n",
    "if not wav2lip_dir.exists():\n",
    "    print(\"üì• Cloning Wav2Lip...\")\n",
    "    !git clone -q --depth=1 https://github.com/Rudrabha/Wav2Lip.git {wav2lip_dir}\n",
    "    # FIX: Don't install requirements.txt - deps already covered\n",
    "else:\n",
    "    print(\"‚úì Wav2Lip already installed\")\n",
    "\n",
    "print(\"\\n‚úÖ External dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-models",
   "metadata": {
    "id": "section-5-models"
   },
   "source": [
    "## 5Ô∏è‚É£ Download Model Checkpoints\n",
    "\n",
    "**CRITICAL FIX**: Using the official download script to get the COMPLETE model set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-models-dir",
   "metadata": {
    "id": "setup-models-dir"
   },
   "outputs": [],
   "source": [
    "# Setup models directory\n",
    "MODELS_DIR = Path(\"/content/models\")\n",
    "\n",
    "# Uncomment to use Google Drive (persistent storage)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# MODELS_DIR = Path(\"/content/drive/MyDrive/avatar-renderer-models\")\n",
    "\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "os.environ['MODEL_ROOT'] = str(MODELS_DIR)\n",
    "\n",
    "print(f\"üìÅ Models directory: {MODELS_DIR}\")\n",
    "print(f\"Storage: {'Google Drive (persistent)' if 'drive' in str(MODELS_DIR) else 'Colab storage (temporary)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-models",
   "metadata": {
    "id": "download-models"
   },
   "outputs": [],
   "source": [
    "# Download models using the official script (FIX: ensures all required models are downloaded)\n",
    "print(\"üì• Downloading model checkpoints using official script...\")\n",
    "print(\"This ensures all required models are downloaded correctly.\\n\")\n",
    "\n",
    "# Use the repo's official download script\n",
    "!bash {REPO_DIR}/scripts/download_models.sh {MODELS_DIR}\n",
    "\n",
    "# Verify critical models exist\n",
    "required_models = [\n",
    "    MODELS_DIR / \"sadtalker\" / \"sadtalker.pth\",\n",
    "    MODELS_DIR / \"wav2lip\" / \"wav2lip_gan.pth\",\n",
    "    MODELS_DIR / \"gfpgan\" / \"GFPGANv1.3.pth\",  # FIX: v1.3 not v1.4\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Verifying model downloads:\")\n",
    "all_exist = True\n",
    "for model_path in required_models:\n",
    "    if model_path.exists():\n",
    "        size_mb = model_path.stat().st_size / (1024*1024)\n",
    "        print(f\"  ‚úÖ {model_path.name} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {model_path.name} - NOT FOUND\")\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(\"\\n‚úÖ All required models downloaded successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some models missing. Real-time mode may still work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6-setup",
   "metadata": {
    "id": "section-6-setup"
   },
   "source": [
    "## 6Ô∏è‚É£ Configure Environment & MCP Server\n",
    "\n",
    "**CRITICAL FIX**: Setting correct PYTHONPATH and EXT_DEPS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-env",
   "metadata": {
    "id": "setup-env"
   },
   "outputs": [],
   "source": [
    "# Configure environment variables (FIX: proper PYTHONPATH)\n",
    "import sys\n",
    "import torch  # FIX: Import torch explicitly\n",
    "\n",
    "print(\"‚öôÔ∏è Configuring environment...\\n\")\n",
    "\n",
    "# Set environment variables\n",
    "env_vars = {\n",
    "    'MODEL_ROOT': str(MODELS_DIR),\n",
    "    'EXT_DEPS_DIR': str(EXT_DEPS_DIR),  # FIX: Add EXT_DEPS_DIR\n",
    "    'LOG_LEVEL': 'INFO',\n",
    "    'TMP_DIR': '/tmp',\n",
    "    'CUDA_VISIBLE_DEVICES': '0' if torch.cuda.is_available() else '',\n",
    "}\n",
    "\n",
    "for key, value in env_vars.items():\n",
    "    os.environ[key] = value\n",
    "    print(f\"‚úì {key}={value[:60]}{'...' if len(value) > 60 else ''}\")\n",
    "\n",
    "# FIX: Add external deps to Python path correctly\n",
    "paths_to_add = [\n",
    "    str(REPO_DIR),\n",
    "    str(EXT_DEPS_DIR),\n",
    "    str(EXT_DEPS_DIR / \"SadTalker\"),\n",
    "    str(EXT_DEPS_DIR / \"Wav2Lip\"),\n",
    "    str(EXT_DEPS_DIR / \"first-order-model\"),\n",
    "]\n",
    "\n",
    "for path in paths_to_add:\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "print(f\"\\n‚úÖ Python path configured with {len(paths_to_add)} directories\")\n",
    "print(\"‚úÖ Environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-imports",
   "metadata": {
    "id": "verify-imports"
   },
   "outputs": [],
   "source": "# Verify imports\nprint(\"üß™ Verifying installation...\\n\")\n\nerrors = []\n\ntry:\n    from app.pipeline import render_pipeline\n    print(\"‚úÖ Pipeline module\")\nexcept Exception as e:\n    print(f\"‚ùå Pipeline module: {e}\")\n    errors.append(str(e))\n\ntry:\n    from app.settings import settings\n    print(\"‚úÖ Settings module\")\n    print(f\"   Model root: {settings.MODEL_ROOT}\")\nexcept Exception as e:\n    print(f\"‚ùå Settings module: {e}\")\n    errors.append(str(e))\n\n# Check key dependencies\ndeps = ['torch', 'torchvision', 'diffusers', 'transformers', 'librosa']\nfor dep in deps:\n    try:\n        __import__(dep)\n        print(f\"‚úÖ {dep}\")\n    except ImportError as e:\n        print(f\"‚ùå {dep}: {e}\")\n        errors.append(f\"{dep}: {e}\")\n\n# Check gfpgan separately (may have compatibility issues with newer torchvision)\ntry:\n    import gfpgan\n    print(\"‚úÖ gfpgan\")\nexcept ImportError as e:\n    print(f\"‚ö†Ô∏è  gfpgan: {e}\")\n    print(\"   (Face enhancement may be unavailable, but core features will work)\")\n\nif not errors:\n    print(\"\\n‚úÖ All components verified!\")\n    print(\"üé¨ Ready to generate avatars!\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  {len(errors)} errors found\")\n    print(\"Some features may not work. Try re-running installation cells.\")"
  },
  {
   "cell_type": "markdown",
   "id": "section-7-demo",
   "metadata": {
    "id": "section-7-demo"
   },
   "source": [
    "## 7Ô∏è‚É£ Generate Hello World Avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-output",
   "metadata": {
    "id": "setup-output"
   },
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "OUTPUT_DIR = Path(\"/content/avatar_outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Check test assets\n",
    "test_image = REPO_DIR / \"tests/assets/alice.png\"\n",
    "test_audio = REPO_DIR / \"tests/assets/hello.wav\"\n",
    "\n",
    "print(\"üìÅ Output directory:\", OUTPUT_DIR)\n",
    "print(\"\\nüé® Test assets:\")\n",
    "\n",
    "if test_image.exists():\n",
    "    print(f\"  ‚úÖ Image: {test_image.name}\")\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=str(test_image), width=300))\n",
    "else:\n",
    "    print(f\"  ‚ùå Image not found\")\n",
    "\n",
    "if test_audio.exists():\n",
    "    print(f\"  ‚úÖ Audio: {test_audio.name}\")\n",
    "    from IPython.display import Audio, display\n",
    "    display(Audio(filename=str(test_audio)))\n",
    "else:\n",
    "    print(f\"  ‚ùå Audio not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-avatar",
   "metadata": {
    "id": "generate-avatar"
   },
   "outputs": [],
   "source": [
    "# Generate avatar\n",
    "import time\n",
    "from IPython.display import Video, display\n",
    "from app.pipeline import render_pipeline\n",
    "\n",
    "output_video = OUTPUT_DIR / \"hello_world.mp4\"\n",
    "\n",
    "print(\"üé¨ Generating 'Hello World' Avatar\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Image: {test_image.name}\")\n",
    "print(f\"Audio: {test_audio.name}\")\n",
    "print(f\"Quality: auto (adapts to available hardware)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚è≥ Processing...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    result = render_pipeline(\n",
    "        face_image=str(test_image),\n",
    "        audio=str(test_audio),\n",
    "        out_path=str(output_video),\n",
    "        quality_mode=\"auto\"\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚úÖ SUCCESS!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"‚è±Ô∏è  Time: {elapsed:.1f}s\")\n",
    "    print(f\"üìÅ File: {result}\")\n",
    "    print(f\"üìä Size: {Path(result).stat().st_size / (1024*1024):.2f} MB\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    print(\"üé• Your AI Avatar:\")\n",
    "    display(Video(result, width=640, embed=True))\n",
    "    \n",
    "except Exception as e:\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚ùå ERROR\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(f\"Time: {elapsed:.1f}s\")\n",
    "    print(f\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Check models downloaded correctly (Section 5)\")\n",
    "    print(\"2. Verify test assets exist (Section 7)\")\n",
    "    print(\"3. Try quality_mode='real_time' for CPU systems\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    import traceback\n",
    "    print(\"\\nüìã Full error:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8-custom",
   "metadata": {
    "id": "section-8-custom"
   },
   "source": [
    "## 8Ô∏è‚É£ Create Custom Avatars\n",
    "\n",
    "Upload your own files or use different quality modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-files",
   "metadata": {
    "id": "upload-files"
   },
   "outputs": [],
   "source": [
    "# Upload custom files\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    import shutil\n",
    "    \n",
    "    UPLOAD_DIR = Path(\"/content/uploads\")\n",
    "    UPLOAD_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"üì§ Upload your files (image + audio):\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        dst = UPLOAD_DIR / filename\n",
    "        shutil.move(filename, str(dst))\n",
    "        print(f\"‚úÖ {filename}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  File upload only works in Colab\")\n",
    "    UPLOAD_DIR = REPO_DIR / \"tests/assets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-custom",
   "metadata": {
    "id": "generate-custom"
   },
   "outputs": [],
   "source": [
    "# Generate from uploaded files\n",
    "image_files = list(UPLOAD_DIR.glob(\"*.png\")) + list(UPLOAD_DIR.glob(\"*.jpg\"))\n",
    "audio_files = list(UPLOAD_DIR.glob(\"*.wav\")) + list(UPLOAD_DIR.glob(\"*.mp3\"))\n",
    "\n",
    "if image_files and audio_files:\n",
    "    custom_output = OUTPUT_DIR / \"custom_avatar.mp4\"\n",
    "    \n",
    "    print(f\"üé¨ Generating from: {image_files[0].name} + {audio_files[0].name}\")\n",
    "    \n",
    "    result = render_pipeline(\n",
    "        face_image=str(image_files[0]),\n",
    "        audio=str(audio_files[0]),\n",
    "        out_path=str(custom_output),\n",
    "        quality_mode=\"auto\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Custom avatar generated!\")\n",
    "    display(Video(result, width=640, embed=True))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Upload both image and audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9-download",
   "metadata": {
    "id": "section-9-download"
   },
   "source": [
    "## 9Ô∏è‚É£ Download Generated Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-videos",
   "metadata": {
    "id": "download-videos"
   },
   "outputs": [],
   "source": [
    "# Download videos\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    videos = list(OUTPUT_DIR.glob(\"*.mp4\"))\n",
    "    \n",
    "    if videos:\n",
    "        print(\"üì• Available videos:\")\n",
    "        for video in videos:\n",
    "            size_mb = video.stat().st_size / (1024*1024)\n",
    "            print(f\"  üìπ {video.name} ({size_mb:.2f} MB)\")\n",
    "        \n",
    "        print(\"\\nüíæ Downloading...\")\n",
    "        for video in videos:\n",
    "            files.download(str(video))\n",
    "            print(f\"‚úÖ {video.name}\")\n",
    "    else:\n",
    "        print(\"No videos found. Generate some first!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Download only works in Colab\")\n",
    "    print(f\"Videos saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-10-summary",
   "metadata": {
    "id": "section-10-summary"
   },
   "source": [
    "## üéâ Summary\n",
    "\n",
    "### What Was Fixed\n",
    "\n",
    "‚úÖ **Python 3.10+ compatibility** - Updated pyproject.toml\n",
    "\n",
    "‚úÖ **Dependency conflicts resolved** - Preserved Colab's torch, loosened version constraints\n",
    "\n",
    "‚úÖ **External repos handled safely** - Cloned without breaking torch installation\n",
    "\n",
    "‚úÖ **Complete model downloads** - Used official script for all required models\n",
    "\n",
    "‚úÖ **GFPGAN version standardized** - v1.3 across all components\n",
    "\n",
    "‚úÖ **Import issues fixed** - Dynamic loading for SadTalker/Wav2Lip/FOMM\n",
    "\n",
    "‚úÖ **PYTHONPATH configured** - All external deps properly added\n",
    "\n",
    "‚úÖ **Missing imports added** - torch imported where needed\n",
    "\n",
    "‚úÖ **gdown installed** - Available when needed\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- **GPU**: Enable for 5-10x speedup\n",
    "- **Real-time mode**: Fast, works on CPU\n",
    "- **High-quality mode**: Best results, requires GPU\n",
    "- **Google Drive**: Mount for persistent model storage\n",
    "\n",
    "### Support\n",
    "\n",
    "- **Website**: [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "- **Repository**: [https://github.com/ruslanmv/avatar-renderer-mcp](https://github.com/ruslanmv/avatar-renderer-mcp)\n",
    "- **Issues**: [GitHub Issues](https://github.com/ruslanmv/avatar-renderer-mcp/issues)\n",
    "\n",
    "---\n",
    "\n",
    "*Made with ‚ù§Ô∏è by [Ruslan Magana Vsevolodovna](https://ruslanmv.com)*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}