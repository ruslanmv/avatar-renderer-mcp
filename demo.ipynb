{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Avatar Renderer MCP - Demo Notebook\n",
    "\n",
    "**Transform static images into dynamic AI-powered avatars with realistic expressions and voice synchronization**\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Install and set up Avatar Renderer MCP\n",
    "2. Generate your first \"Hello World\" talking avatar\n",
    "3. Create professional demo videos for marketing\n",
    "4. Use different quality modes (real-time vs high-quality)\n",
    "\n",
    "---\n",
    "\n",
    "**Website:** [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "\n",
    "**Repository:** [https://github.com/ruslanmv/avatar-renderer-mcp](https://github.com/ruslanmv/avatar-renderer-mcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-install",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup\n",
    "\n",
    "First, let's install the package and its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-uv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv package manager (if not already installed)\n",
    "!pip install -q uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install avatar-renderer-mcp and dependencies\n",
    "# Note: This assumes you're in the repository root directory\n",
    "!uv pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-git-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install external dependencies (SadTalker, Wav2Lip, etc.)\n",
    "# This may take a few minutes\n",
    "!make install-git-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-imports",
   "metadata": {},
   "source": [
    "## 2. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from IPython.display import Video, HTML, display\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add external dependencies to Python path\n",
    "ext_deps = Path.cwd() / \"external_deps\"\n",
    "if ext_deps.exists():\n",
    "    sys.path.insert(0, str(ext_deps))\n",
    "    print(f\"‚úì Added external dependencies: {ext_deps}\")\n",
    "\n",
    "# Import the pipeline\n",
    "from app.pipeline import render_pipeline\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"GPU Available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Using CPU mode (slower but works).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-directories",
   "metadata": {},
   "source": [
    "## 3. Setup Directories & Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-dirs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for generated videos\n",
    "output_dir = Path(\"demo_outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"‚úì Output directory: {output_dir.absolute()}\")\n",
    "\n",
    "# Check for test assets\n",
    "test_image = Path(\"tests/assets/alice.png\")\n",
    "test_audio = Path(\"tests/assets/hello.wav\")\n",
    "\n",
    "if test_image.exists() and test_audio.exists():\n",
    "    print(f\"‚úì Found test assets:\")\n",
    "    print(f\"  - Image: {test_image}\")\n",
    "    print(f\"  - Audio: {test_audio}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Test assets not found. You'll need to provide your own image and audio files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-hello-world",
   "metadata": {},
   "source": [
    "## 4. Hello World - Your First Avatar!\n",
    "\n",
    "Let's create a simple \"Hello World\" talking avatar. This uses the test assets included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hello-world-generate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Hello World video\n",
    "output_video = output_dir / \"hello_world.mp4\"\n",
    "\n",
    "print(\"üé¨ Generating Hello World avatar...\")\n",
    "print(\"This may take 30-60 seconds depending on your hardware...\\n\")\n",
    "\n",
    "try:\n",
    "    result = render_pipeline(\n",
    "        face_image=str(test_image),\n",
    "        audio=str(test_audio),\n",
    "        out_path=str(output_video),\n",
    "        quality_mode=\"auto\"  # Automatically selects best mode for your hardware\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Success! Video saved to: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Make sure models are downloaded: make download-models\")\n",
    "    print(\"2. Check GPU availability if using high-quality mode\")\n",
    "    print(\"3. Try quality_mode='real_time' for CPU-only systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hello-world-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated video\n",
    "if output_video.exists():\n",
    "    print(\"üé• Your first AI avatar:\")\n",
    "    display(Video(str(output_video), width=640, embed=True))\n",
    "else:\n",
    "    print(\"Video file not found. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-custom-demo",
   "metadata": {},
   "source": [
    "## 5. Create Custom Demo Videos\n",
    "\n",
    "Now let's create professional demo videos for your website. You can use your own images and audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-demo-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display videos inline\n",
    "def display_video(video_path, title=\"Generated Video\", width=640):\n",
    "    \"\"\"Display video with title\"\"\"\n",
    "    if Path(video_path).exists():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üé¨ {title}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        display(Video(str(video_path), width=width, embed=True))\n",
    "        file_size = Path(video_path).stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"\\nüìä File size: {file_size:.2f} MB\")\n",
    "        print(f\"üìÅ Location: {video_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Video not found: {video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-professional-avatar",
   "metadata": {},
   "source": [
    "### Example 1: Professional Avatar (Customer Support)\n",
    "\n",
    "Perfect for:\n",
    "- Customer support representatives\n",
    "- Company announcements\n",
    "- Professional presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a professional customer support avatar\n",
    "# Replace these paths with your own assets\n",
    "\n",
    "professional_video = output_dir / \"professional_demo.mp4\"\n",
    "\n",
    "print(\"üé¨ Creating professional customer support avatar...\")\n",
    "\n",
    "# Using the test assets as an example\n",
    "# In production, you'd use: your_image.png and your_script.wav\n",
    "try:\n",
    "    result = render_pipeline(\n",
    "        face_image=str(test_image),\n",
    "        audio=str(test_audio),\n",
    "        out_path=str(professional_video),\n",
    "        quality_mode=\"high_quality\"  # Best quality for professional content\n",
    "    )\n",
    "    display_video(result, \"Professional Customer Support Avatar\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  High-quality mode failed: {e}\")\n",
    "    print(\"Trying real-time mode instead...\")\n",
    "    result = render_pipeline(\n",
    "        face_image=str(test_image),\n",
    "        audio=str(test_audio),\n",
    "        out_path=str(professional_video),\n",
    "        quality_mode=\"real_time\"\n",
    "    )\n",
    "    display_video(result, \"Professional Customer Support Avatar (Real-time Mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-real-time",
   "metadata": {},
   "source": [
    "### Example 2: Real-Time Avatar (Live Streaming)\n",
    "\n",
    "Perfect for:\n",
    "- Live news broadcasts\n",
    "- Real-time chatbots\n",
    "- Interactive virtual assistants\n",
    "\n",
    "**Target: <3s latency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realtime-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "realtime_video = output_dir / \"realtime_demo.mp4\"\n",
    "\n",
    "print(\"‚ö° Creating real-time avatar (optimized for speed)...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = render_pipeline(\n",
    "    face_image=str(test_image),\n",
    "    audio=str(test_audio),\n",
    "    out_path=str(realtime_video),\n",
    "    quality_mode=\"real_time\"  # Fast processing for streaming\n",
    ")\n",
    "\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Processing time: {processing_time:.2f} seconds\")\n",
    "display_video(result, \"Real-Time Avatar (Live Streaming Ready)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-comparison",
   "metadata": {},
   "source": [
    "## 6. Quality Mode Comparison\n",
    "\n",
    "Let's compare the two quality modes:\n",
    "\n",
    "| Feature | Real-Time | High-Quality |\n",
    "|---------|-----------|-------------|\n",
    "| **Speed** | <3s | ~10-30s |\n",
    "| **GPU Required** | No | Yes |\n",
    "| **Bitrate** | 2 Mbps | 6 Mbps |\n",
    "| **Enhancement** | None | GFPGAN |\n",
    "| **Best For** | Live streaming | Pre-recorded content |\n",
    "| **Pipeline** | SadTalker + Wav2Lip | FOMM + Diff2Lip + GFPGAN |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-custom-content",
   "metadata": {},
   "source": [
    "## 7. Create Your Own Content\n",
    "\n",
    "Ready to create your own avatar videos? Here's a template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-content-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for creating your own avatar videos\n",
    "\n",
    "def create_custom_avatar(\n",
    "    image_path: str,\n",
    "    audio_path: str,\n",
    "    output_name: str,\n",
    "    quality: str = \"auto\",\n",
    "    description: str = \"Custom Avatar\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a custom avatar video\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to avatar image (PNG/JPG)\n",
    "        audio_path: Path to audio file (WAV/MP3)\n",
    "        output_name: Name for output video (without extension)\n",
    "        quality: 'real_time', 'high_quality', or 'auto'\n",
    "        description: Description for display\n",
    "    \"\"\"\n",
    "    output_path = output_dir / f\"{output_name}.mp4\"\n",
    "    \n",
    "    print(f\"üé¨ Creating {description}...\")\n",
    "    print(f\"   Image: {image_path}\")\n",
    "    print(f\"   Audio: {audio_path}\")\n",
    "    print(f\"   Quality: {quality}\\n\")\n",
    "    \n",
    "    try:\n",
    "        result = render_pipeline(\n",
    "            face_image=image_path,\n",
    "            audio=audio_path,\n",
    "            out_path=str(output_path),\n",
    "            quality_mode=quality\n",
    "        )\n",
    "        display_video(result, description)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úì Custom avatar function ready!\")\n",
    "print(\"\\nUsage example:\")\n",
    "print('create_custom_avatar(')\n",
    "print('    image_path=\"path/to/your/image.png\",')\n",
    "print('    audio_path=\"path/to/your/audio.wav\",')\n",
    "print('    output_name=\"my_avatar\",')\n",
    "print('    quality=\"high_quality\",')\n",
    "print('    description=\"My Custom Avatar\"')\n",
    "print(')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create your own avatar\n",
    "# Uncomment and modify the paths below:\n",
    "\n",
    "# create_custom_avatar(\n",
    "#     image_path=\"path/to/your/image.png\",\n",
    "#     audio_path=\"path/to/your/audio.wav\",\n",
    "#     output_name=\"my_first_avatar\",\n",
    "#     quality=\"auto\",\n",
    "#     description=\"My First Custom Avatar\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-tips",
   "metadata": {},
   "source": [
    "## 8. Tips for Creating Great Demo Videos\n",
    "\n",
    "### üñºÔ∏è Image Requirements\n",
    "- **Format**: PNG or JPG\n",
    "- **Face**: Clear, front-facing portrait\n",
    "- **Resolution**: Minimum 512x512, recommended 1024x1024\n",
    "- **Lighting**: Well-lit, avoid harsh shadows\n",
    "- **Background**: Clean, uncluttered\n",
    "\n",
    "### üé§ Audio Requirements\n",
    "- **Format**: WAV or MP3\n",
    "- **Sample Rate**: 16kHz recommended\n",
    "- **Quality**: Clear speech, minimal background noise\n",
    "- **Length**: Keep it concise (10-30 seconds for demos)\n",
    "\n",
    "### üé¨ Demo Video Best Practices\n",
    "1. **Keep it short**: 5-15 seconds for website demos\n",
    "2. **Clear message**: Focus on one key benefit\n",
    "3. **Professional appearance**: Use high-quality mode for marketing\n",
    "4. **Multiple variations**: Create videos for different use cases\n",
    "5. **Test on different devices**: Ensure compatibility\n",
    "\n",
    "### üìä Recommended Demo Topics\n",
    "1. **Customer Support**: \"Hello! I'm here to help you 24/7\"\n",
    "2. **AI Teacher**: \"Welcome to today's lesson on...\"\n",
    "3. **Brand Ambassador**: \"Discover our latest product...\"\n",
    "4. **Game NPC**: \"Greetings, traveler! What brings you here?\"\n",
    "5. **News Anchor**: \"Good evening, here are today's top stories...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-batch",
   "metadata": {},
   "source": [
    "## 9. Batch Processing (Multiple Videos)\n",
    "\n",
    "Create multiple demo videos at once for your website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_create_demos(demos_config):\n",
    "    \"\"\"\n",
    "    Create multiple demo videos from a configuration list\n",
    "    \n",
    "    Args:\n",
    "        demos_config: List of dictionaries with demo configurations\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"üé¨ Starting batch creation of {len(demos_config)} videos...\\n\")\n",
    "    \n",
    "    for i, config in enumerate(demos_config, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing {i}/{len(demos_config)}: {config['name']}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        result = create_custom_avatar(\n",
    "            image_path=config['image'],\n",
    "            audio_path=config['audio'],\n",
    "            output_name=config['output'],\n",
    "            quality=config.get('quality', 'auto'),\n",
    "            description=config['name']\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'name': config['name'],\n",
    "            'output': result,\n",
    "            'success': result is not None\n",
    "        })\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(\"üìä BATCH PROCESSING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    print(f\"‚úÖ Successful: {successful}/{len(results)}\")\n",
    "    \n",
    "    if successful < len(results):\n",
    "        print(f\"‚ùå Failed: {len(results) - successful}\")\n",
    "        print(\"\\nFailed videos:\")\n",
    "        for r in results:\n",
    "            if not r['success']:\n",
    "                print(f\"  - {r['name']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example configuration for multiple demos\n",
    "demo_configs = [\n",
    "    {\n",
    "        'name': 'Hello World Demo',\n",
    "        'image': str(test_image),\n",
    "        'audio': str(test_audio),\n",
    "        'output': 'demo_1_hello',\n",
    "        'quality': 'auto'\n",
    "    },\n",
    "    # Add more demos here:\n",
    "    # {\n",
    "    #     'name': 'Customer Support Demo',\n",
    "    #     'image': 'assets/support_avatar.png',\n",
    "    #     'audio': 'assets/support_script.wav',\n",
    "    #     'output': 'demo_2_support',\n",
    "    #     'quality': 'high_quality'\n",
    "    # },\n",
    "]\n",
    "\n",
    "# Uncomment to run batch processing:\n",
    "# results = batch_create_demos(demo_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-api-reference",
   "metadata": {},
   "source": [
    "## 10. API Reference\n",
    "\n",
    "### Core Function: `render_pipeline()`\n",
    "\n",
    "```python\n",
    "render_pipeline(\n",
    "    face_image: str,           # Path to avatar image (PNG/JPG)\n",
    "    audio: str,                # Path to audio file (WAV/MP3)\n",
    "    out_path: str,             # Output video path\n",
    "    reference_video: str = None,  # Optional driving video\n",
    "    quality_mode: str = \"auto\"    # \"real_time\", \"high_quality\", or \"auto\"\n",
    ") -> str  # Returns absolute path to generated video\n",
    "```\n",
    "\n",
    "### Quality Modes\n",
    "\n",
    "#### `real_time`\n",
    "- **Speed**: <3 seconds latency\n",
    "- **Pipeline**: SadTalker + Wav2Lip\n",
    "- **GPU**: Optional (CPU fallback available)\n",
    "- **Use cases**: Live streaming, chatbots, real-time interactions\n",
    "\n",
    "#### `high_quality`\n",
    "- **Quality**: Maximum with GFPGAN enhancement\n",
    "- **Pipeline**: FOMM + Diff2Lip + GFPGAN\n",
    "- **GPU**: Required (V100 or better recommended)\n",
    "- **Use cases**: YouTube content, marketing videos, professional productions\n",
    "\n",
    "#### `auto` (default)\n",
    "- Automatically selects the best mode based on:\n",
    "  - GPU availability\n",
    "  - Model checkpoint availability\n",
    "  - System resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-next-steps",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "### üìö Learn More\n",
    "- Read the full documentation: [README.md](README.md)\n",
    "- Explore quality modes: [docs/QUALITY_MODES.md](docs/QUALITY_MODES.md)\n",
    "- Check out the API: Start the FastAPI server with `make run`\n",
    "\n",
    "### üöÄ Deploy to Production\n",
    "1. **Docker**: `make docker-build && make docker-run`\n",
    "2. **Kubernetes**: `helm install avatar-renderer ./charts/avatar-renderer`\n",
    "3. **Frontend**: Deploy the Next.js app from `/frontend` to Vercel\n",
    "\n",
    "### üé® Create More Content\n",
    "1. Prepare your avatar images and scripts\n",
    "2. Use this notebook to generate demo videos\n",
    "3. Upload to your website at [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "\n",
    "### üí° Advanced Features\n",
    "- **MCP Integration**: Use the STDIO server for AI agent communication\n",
    "- **REST API**: Integrate with your applications via FastAPI\n",
    "- **Custom Models**: Fine-tune models for your specific use case\n",
    "- **Batch Processing**: Process multiple videos efficiently\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully created your first AI-powered talking avatar!\n",
    "\n",
    "**Need help?** Check out:\n",
    "- üåê Website: [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "- üì¶ Repository: [https://github.com/ruslanmv/avatar-renderer-mcp](https://github.com/ruslanmv/avatar-renderer-mcp)\n",
    "- üìß Contact: contact@ruslanmv.com\n",
    "- üåü Author: [Ruslan Magana Vsevolodovna](https://ruslanmv.com)\n",
    "\n",
    "---\n",
    "\n",
    "*Transform static images into dynamic, AI-powered avatars with realistic expressions and voice synchronization*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
