{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Avatar Renderer MCP - Demo Notebook\n",
    "\n",
    "**Transform static images into dynamic AI-powered avatars with realistic expressions and voice synchronization**\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Install and set up Avatar Renderer MCP\n",
    "2. Generate your first \"Hello World\" talking avatar\n",
    "3. Create professional demo videos for marketing\n",
    "4. Use different quality modes (real-time vs high-quality)\n",
    "\n",
    "---\n",
    "\n",
    "**Website:** [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "\n",
    "**Repository:** [https://github.com/ruslanmv/avatar-renderer-mcp](https://github.com/ruslanmv/avatar-renderer-mcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-install",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup\n",
    "\n",
    "First, let's install the package and its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-uv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv package manager (if not already installed)\n",
    "!pip install -q uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install avatar-renderer-mcp and dependencies\n",
    "# Note: This assumes you're in the repository root directory\n",
    "!uv pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-git-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install external dependencies (SadTalker, Wav2Lip, etc.)\n",
    "# This may take a few minutes\n",
    "!make install-git-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mrvwuhpo70b",
   "source": "### 1.1 Configure Environment & Model Paths\n\n**Critical Step**: Set up MODEL_ROOT to point to the local models directory.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "d63vz9t9ukf",
   "source": "from pathlib import Path\nimport os\n\n# Verify repository root\nrepo_root = Path.cwd()\nprint(f\"Repository root: {repo_root}\")\n\n# Verify environment is configured correctly\n# (These should already be set by the imports cell above)\nmodels_dir = Path(os.environ.get(\"MODEL_ROOT\", repo_root / \"models\"))\next_deps_dir = Path(os.environ.get(\"EXT_DEPS_DIR\", repo_root / \"external_deps\"))\n\nprint(f\"\\n‚úì Configuration verified:\")\nprint(f\"  MODEL_ROOT   = {models_dir}\")\nprint(f\"  EXT_DEPS_DIR = {ext_deps_dir}\")\nprint(f\"  Models exist: {models_dir.exists()}\")\nprint(f\"  Ext deps exist: {ext_deps_dir.exists()}\")\n\nif not models_dir.exists():\n    print(\"\\n‚ö†Ô∏è  Models directory not found! Run: !make download-models\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e2x5qo8km3u",
   "source": "# Download models if not present\n!make download-models",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "section-imports",
   "metadata": {},
   "source": [
    "## 2. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nfrom pathlib import Path\nfrom IPython.display import Video, HTML, display\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# CRITICAL: Set environment variables BEFORE importing pipeline\n# This ensures the pipeline module sees the correct MODEL_ROOT path\nrepo_root = Path.cwd()\nmodels_dir = repo_root / \"models\"\next_deps_dir = repo_root / \"external_deps\"\n\nos.environ[\"MODEL_ROOT\"] = str(models_dir.resolve())\nos.environ[\"EXT_DEPS_DIR\"] = str(ext_deps_dir.resolve())\n\nprint(f\"‚úì Environment configured:\")\nprint(f\"  MODEL_ROOT   = {os.environ['MODEL_ROOT']}\")\nprint(f\"  EXT_DEPS_DIR = {os.environ['EXT_DEPS_DIR']}\")\n\n# Add external dependencies to Python path\nif ext_deps_dir.exists():\n    sys.path.insert(0, str(ext_deps_dir))\n    # Also add subdirectories for external repos (critical for FOMM, SadTalker, Wav2Lip)\n    for subdir in [\"first-order-model\", \"SadTalker\", \"Wav2Lip\"]:\n        subpath = ext_deps_dir / subdir\n        if subpath.exists():\n            sys.path.insert(0, str(subpath))\n    print(f\"‚úì Added external dependencies: {ext_deps_dir}\")\n\n# NOW import the pipeline (after env vars are set)\nfrom app.pipeline import render_pipeline\n\nprint(\"‚úì All imports successful!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"GPU Available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Using CPU mode (slower but works).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-directories",
   "metadata": {},
   "source": [
    "## 3. Setup Directories & Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-dirs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for generated videos\n",
    "output_dir = Path(\"demo_outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"‚úì Output directory: {output_dir.absolute()}\")\n",
    "\n",
    "# Check for test assets\n",
    "test_image = Path(\"tests/assets/alice.png\")\n",
    "test_audio = Path(\"tests/assets/hello.wav\")\n",
    "\n",
    "if test_image.exists() and test_audio.exists():\n",
    "    print(f\"‚úì Found test assets:\")\n",
    "    print(f\"  - Image: {test_image}\")\n",
    "    print(f\"  - Audio: {test_audio}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Test assets not found. You'll need to provide your own image and audio files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3lmyae095mp",
   "source": "### 3.1 Download Frontend Avatar Presets\n\nDownload the same avatar presets used in the frontend website for consistent demos.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7kswzywfvar",
   "source": "from pathlib import Path\nfrom urllib.parse import quote\nimport time\nimport random\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\nfrom PIL import Image\nfrom io import BytesIO\n\n# Configure avatar preset directory\nAVATAR_DIR = Path(\"notebook_assets/avatars\")\nAVATAR_DIR.mkdir(parents=True, exist_ok=True)\n\nPOLLINATIONS_BASE = \"https://image.pollinations.ai/prompt/\"\n\ndef pollinations_url(prompt: str, width: int = 768, height: int = 768, nologo: bool = True) -> str:\n    \"\"\"Generate Pollinations AI image URL from prompt\"\"\"\n    return f\"{POLLINATIONS_BASE}{quote(prompt)}?width={width}&height={height}&nologo={'true' if nologo else 'false'}\"\n\n# Frontend avatar presets (matching the website)\nFRONTEND_PRESETS = [\n    {\n        \"id\": \"professional\",\n        \"name\": \"Professional\",\n        \"desc\": \"Support ‚Ä¢ Sales ‚Ä¢ HR\",\n        \"prompt\": \"professional business portrait photography, studio lighting, neutral background, sharp focus, high detail\",\n    },\n    {\n        \"id\": \"creator\",\n        \"name\": \"Creator\",\n        \"desc\": \"Influencer ‚Ä¢ Ads\",\n        \"prompt\": \"casual portrait of a young content creator, natural lighting, lifestyle photography, friendly smile, high detail\",\n    },\n    {\n        \"id\": \"educator\",\n        \"name\": \"Educator\",\n        \"desc\": \"Courses ‚Ä¢ Tutors\",\n        \"prompt\": \"teacher portrait, friendly professional educator, classroom or education setting, soft lighting, high detail\",\n    },\n    {\n        \"id\": \"npc\",\n        \"name\": \"Game NPC\",\n        \"desc\": \"Dialogue ‚Ä¢ Lore\",\n        \"prompt\": \"3d render game character portrait, fantasy rpg style, detailed, cinematic lighting, centered face\",\n    },\n    {\n        \"id\": \"brand\",\n        \"name\": \"Brand\",\n        \"desc\": \"Retail ‚Ä¢ Events\",\n        \"prompt\": \"brand ambassador professional corporate portrait, confident, clean background, studio lighting, high detail\",\n    },\n    {\n        \"id\": \"custom\",\n        \"name\": \"Custom\",\n        \"desc\": \"Bring your own\",\n        \"prompt\": \"futuristic cyberpunk portrait, neon lights, sci-fi style, centered face, high detail\",\n    },\n]\n\ndef _requests_session_with_retries() -> requests.Session:\n    \"\"\"\n    Create a requests session that retries on common transient HTTP failures\n    (including 502 Bad Gateway).\n    \"\"\"\n    retry = Retry(\n        total=8,\n        connect=8,\n        read=8,\n        backoff_factor=0.8,  # exponential backoff\n        status_forcelist=[429, 500, 502, 503, 504],\n        allowed_methods=[\"GET\"],\n        raise_on_status=False,\n    )\n    adapter = HTTPAdapter(max_retries=retry)\n    s = requests.Session()\n    s.mount(\"http://\", adapter)\n    s.mount(\"https://\", adapter)\n    return s\n\nSESSION = _requests_session_with_retries()\n\ndef download_image(url: str, out_path: Path, timeout: int = 120) -> Path:\n    \"\"\"Download image from URL and save as PNG\"\"\"\n    r = SESSION.get(url, timeout=timeout)\n    if r.status_code >= 400:\n        # Force a clean error message with status code\n        raise requests.HTTPError(f\"{r.status_code} {r.reason} for url: {url}\", response=r)\n\n    img = Image.open(BytesIO(r.content)).convert(\"RGB\")\n    img.save(out_path, format=\"PNG\")\n    return out_path\n\ndef prepare_frontend_avatars(force_redownload: bool = False):\n    \"\"\"\n    Download frontend avatar presets locally.\n    Uses fallback sizes if 768 fails (some servers struggle under load).\n    \"\"\"\n    local_paths = {}\n\n    # Try big first, then fallback sizes if server is struggling\n    size_fallbacks = [(768, 768), (512, 512), (384, 384)]\n\n    for p in FRONTEND_PRESETS:\n        preset_id = p[\"id\"]\n        out_path = AVATAR_DIR / f\"{preset_id}.png\"\n\n        if out_path.exists() and not force_redownload:\n            print(f\"‚úì {preset_id} already exists: {out_path}\")\n            local_paths[preset_id] = str(out_path)\n            continue\n\n        print(f\"üì• Downloading {preset_id}...\")\n\n        last_err = None\n        for (w, h) in size_fallbacks:\n            url = pollinations_url(p[\"prompt\"], width=w, height=h)\n\n            try:\n                # extra manual jitter between requests helps avoid burst rate-limits\n                time.sleep(0.3 + random.random() * 0.6)\n                download_image(url, out_path, timeout=120)\n                print(f\"   ‚úì Saved to: {out_path}  (size={w}x{h})\")\n                local_paths[preset_id] = str(out_path)\n                last_err = None\n                break\n            except Exception as e:\n                last_err = e\n                print(f\"   ‚ö†Ô∏è Attempt failed at {w}x{h}: {e}\")\n\n        if last_err is not None:\n            print(f\"   ‚ùå Failed to download {preset_id} after fallbacks.\")\n            # continue to next preset, do not kill the notebook\n\n    return local_paths\n\nprint(\"Preparing frontend avatar presets...\\n\")\navatar_files = prepare_frontend_avatars(force_redownload=False)\n\nprint(f\"\\n‚úÖ Ready! Downloaded {len(avatar_files)} avatar presets:\")\nfor preset_id in avatar_files:\n    print(f\"   - {preset_id}: {avatar_files[preset_id]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "section-hello-world",
   "metadata": {},
   "source": [
    "## 4. Hello World - Your First Avatar!\n",
    "\n",
    "Let's create a simple \"Hello World\" talking avatar. This uses the test assets included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hello-world-generate",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport os, sys\nimport torch\n\n# --- Hard requirements for runtime ---\n# Ensure env vars are correct\nREPO_ROOT = Path.cwd()\nos.environ.setdefault(\"MODEL_ROOT\", str((REPO_ROOT / \"models\").resolve()))\nos.environ.setdefault(\"EXT_DEPS_DIR\", str((REPO_ROOT / \"external_deps\").resolve()))\n\nMODEL_ROOT = Path(os.environ[\"MODEL_ROOT\"])\nEXT_DEPS_DIR = Path(os.environ[\"EXT_DEPS_DIR\"])\n\n# Ensure external_deps is importable\nif str(EXT_DEPS_DIR) not in sys.path:\n    sys.path.insert(0, str(EXT_DEPS_DIR))\n\n# --- Check model files ---\nhas_realtime = (MODEL_ROOT/\"sadtalker\"/\"sadtalker.pth\").exists() and (MODEL_ROOT/\"wav2lip\"/\"wav2lip_gan.pth\").exists()\nhas_hq_models = (MODEL_ROOT/\"diff2lip\"/\"Diff2Lip.pth\").exists() and (MODEL_ROOT/\"fomm\"/\"vox-cpk.pth\").exists()\n\n# --- Check external deps needed for HQ ---\nhas_fomm_repo = (EXT_DEPS_DIR/\"first-order-model\").exists()\n# ffmpeg-python import test (needed by first-order-model/demo.py)\ntry:\n    import ffmpeg  # noqa: F401\n    has_ffmpeg_py = True\nexcept Exception:\n    has_ffmpeg_py = False\n\nprint(\"üé¨ Generating Hello World avatar...\")\nprint(\"\\nModel availability:\")\nprint(f\"  - Real-time (SadTalker + Wav2Lip): {'‚úì' if has_realtime else '‚úó'}\")\nprint(f\"  - HQ models (FOMM + Diff2Lip):     {'‚úì' if has_hq_models else '‚úó'}\")\nprint(\"HQ runtime deps:\")\nprint(f\"  - first-order-model repo:         {'‚úì' if has_fomm_repo else '‚úó'}\")\nprint(f\"  - ffmpeg-python module:           {'‚úì' if has_ffmpeg_py else '‚úó'}\")\nprint(f\"  - CUDA available:                 {'‚úì' if torch.cuda.is_available() else '‚úó'}\")\nprint(f\"\\nMODEL_ROOT   = {MODEL_ROOT}\")\nprint(f\"EXT_DEPS_DIR = {EXT_DEPS_DIR}\")\n\n# --- Choose face image (preset if available) ---\nface_image = str(test_image)\nif \"avatar_files\" in globals() and \"professional\" in avatar_files:\n    face_image = avatar_files[\"professional\"]\n\n# --- Render with robust fallback ---\noutput_video = output_dir / \"hello_world.mp4\"\nprint(\"\\nThis may take 30-60 seconds depending on your hardware...\\n\")\n\ntry:\n    # Try HQ only if everything required is truly present\n    if has_hq_models and has_fomm_repo and has_ffmpeg_py and torch.cuda.is_available():\n        print(\"Using high_quality mode...\")\n        result = render_pipeline(\n            face_image=str(face_image),\n            audio=str(test_audio),\n            out_path=str(output_video),\n            quality_mode=\"high_quality\",\n        )\n    elif has_realtime:\n        print(\"Using real_time mode...\")\n        result = render_pipeline(\n            face_image=str(face_image),\n            audio=str(test_audio),\n            out_path=str(output_video),\n            quality_mode=\"real_time\",\n        )\n    else:\n        raise RuntimeError(\n            \"No runnable mode available.\\n\"\n            \"Fix: download models and install external deps.\\n\"\n            \"Run: make install-git-deps && make download-models\"\n        )\n\n    print(f\"\\n‚úÖ Success! Video saved to: {result}\")\n\nexcept Exception as e:\n    print(f\"‚ùå Render failed: {e}\")\n    print(\"\\nTroubleshooting checklist:\")\n    print(\"1) External deps installed?  -> make install-git-deps\")\n    print(\"2) Models downloaded?        -> make download-models\")\n    print(\"3) ffmpeg binary installed?  -> apt-get install ffmpeg (or brew install ffmpeg)\")\n    print(\"4) ffmpeg-python installed?  -> pip install ffmpeg-python\")\n    print(\"5) If no GPU, use real_time\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hello-world-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated video\n",
    "if output_video.exists():\n",
    "    print(\"üé• Your first AI avatar:\")\n",
    "    display(Video(str(output_video), width=640, embed=True))\n",
    "else:\n",
    "    print(\"Video file not found. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-custom-demo",
   "metadata": {},
   "source": [
    "## 5. Create Custom Demo Videos\n",
    "\n",
    "Now let's create professional demo videos for your website. You can use your own images and audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-demo-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display videos inline\n",
    "def display_video(video_path, title=\"Generated Video\", width=640):\n",
    "    \"\"\"Display video with title\"\"\"\n",
    "    if Path(video_path).exists():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üé¨ {title}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        display(Video(str(video_path), width=width, embed=True))\n",
    "        file_size = Path(video_path).stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"\\nüìä File size: {file_size:.2f} MB\")\n",
    "        print(f\"üìÅ Location: {video_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Video not found: {video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-professional-avatar",
   "metadata": {},
   "source": [
    "### Example 1: Professional Avatar (Customer Support)\n",
    "\n",
    "Perfect for:\n",
    "- Customer support representatives\n",
    "- Company announcements\n",
    "- Professional presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-avatar",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport os, sys\nimport torch\n\nprofessional_video = output_dir / \"professional_demo.mp4\"\n\nMODEL_ROOT = Path(os.environ[\"MODEL_ROOT\"])\nEXT_DEPS_DIR = Path(os.environ.get(\"EXT_DEPS_DIR\", \"external_deps\"))\n\n# Ensure external deps importable\nif str(EXT_DEPS_DIR) not in sys.path:\n    sys.path.insert(0, str(EXT_DEPS_DIR))\n\nhas_realtime = (MODEL_ROOT/\"sadtalker\"/\"sadtalker.pth\").exists() and (MODEL_ROOT/\"wav2lip\"/\"wav2lip_gan.pth\").exists()\nhas_hq_models = (MODEL_ROOT/\"diff2lip\"/\"Diff2Lip.pth\").exists() and (MODEL_ROOT/\"fomm\"/\"vox-cpk.pth\").exists()\nhas_fomm_repo = (EXT_DEPS_DIR/\"first-order-model\").exists()\n\ntry:\n    import ffmpeg  # noqa: F401\n    has_ffmpeg_py = True\nexcept Exception:\n    has_ffmpeg_py = False\n\nprint(\"üé¨ Creating professional customer support avatar...\\n\")\nprint(\"Model availability:\")\nprint(f\"  - Real-time mode (SadTalker + Wav2Lip): {'‚úì' if has_realtime else '‚úó'}\")\nprint(f\"  - High-quality models (FOMM + Diff2Lip): {'‚úì' if has_hq_models else '‚úó'}\")\nprint(\"HQ runtime deps:\")\nprint(f\"  - first-order-model repo: {'‚úì' if has_fomm_repo else '‚úó'}\")\nprint(f\"  - ffmpeg-python module:   {'‚úì' if has_ffmpeg_py else '‚úó'}\")\nprint(f\"  - CUDA available:         {'‚úì' if torch.cuda.is_available() else '‚úó'}\\n\")\n\n# Select face image\nif 'avatar_files' in globals() and 'professional' in avatar_files:\n    face_image = avatar_files['professional']\n    print(f\"Using frontend preset avatar: {face_image}\")\nelse:\n    face_image = str(test_image)\n    print(f\"Using test asset: {face_image}\")\n\ndef try_realtime():\n    if not has_realtime:\n        raise RuntimeError(\"Real-time models missing. Run: make download-models\")\n    return render_pipeline(\n        face_image=str(face_image),\n        audio=str(test_audio),\n        out_path=str(professional_video),\n        quality_mode=\"real_time\",\n    )\n\ntry:\n    if has_hq_models and has_fomm_repo and has_ffmpeg_py and torch.cuda.is_available():\n        print(\"\\nAttempting high_quality mode...\")\n        result = render_pipeline(\n            face_image=str(face_image),\n            audio=str(test_audio),\n            out_path=str(professional_video),\n            quality_mode=\"high_quality\",\n        )\n    else:\n        print(\"\\nSkipping high_quality (missing GPU or runtime deps). Using real_time...\")\n        result = try_realtime()\n\n    print(f\"\\n‚úÖ Success! Video saved to: {result}\")\n    display_video(result, \"Professional Avatar\")\n\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è High_quality failed (or pipeline error): {e}\")\n    print(\"\\nFalling back to real_time...\")\n    try:\n        result = try_realtime()\n        print(f\"\\n‚úÖ Success! Video saved to: {result}\")\n        display_video(result, \"Professional Avatar (Real-Time Fallback)\")\n    except Exception as e2:\n        print(f\"‚ùå Fallback also failed: {e2}\")\n        print(\"\\nTroubleshooting:\")\n        print(f\"1. MODEL_ROOT = {MODEL_ROOT}\")\n        print(f\"2. EXT_DEPS_DIR = {EXT_DEPS_DIR}\")\n        print(\"3. Run: make install-git-deps\")\n        print(\"4. Run: make download-models\")\n        print(\"5. Install: pip install ffmpeg-python\")\n        print(\"6. Install system ffmpeg (apt/brew)\")"
  },
  {
   "cell_type": "markdown",
   "id": "section-real-time",
   "metadata": {},
   "source": [
    "### Example 2: Real-Time Avatar (Live Streaming)\n",
    "\n",
    "Perfect for:\n",
    "- Live news broadcasts\n",
    "- Real-time chatbots\n",
    "- Interactive virtual assistants\n",
    "\n",
    "**Target: <3s latency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realtime-avatar",
   "metadata": {},
   "outputs": [],
   "source": "import time\nfrom pathlib import Path\nimport os, sys\n\nrealtime_video = output_dir / \"realtime_demo.mp4\"\n\nMODEL_ROOT = Path(os.environ[\"MODEL_ROOT\"])\nEXT_DEPS_DIR = Path(os.environ.get(\"EXT_DEPS_DIR\", \"external_deps\"))\n\n# Ensure external deps importable\nif str(EXT_DEPS_DIR) not in sys.path:\n    sys.path.insert(0, str(EXT_DEPS_DIR))\n\nprint(\"‚ö° Creating real-time avatar (optimized for speed)...\\n\")\n\n# Check if real-time models are available\nhas_realtime = (MODEL_ROOT/\"sadtalker\"/\"sadtalker.pth\").exists() and (MODEL_ROOT/\"wav2lip\"/\"wav2lip_gan.pth\").exists()\n\nif not has_realtime:\n    print(\"‚ùå Real-time models not available!\")\n    print(f\"\\nMODEL_ROOT: {MODEL_ROOT}\")\n    print(\"\\nRequired files:\")\n    print(f\"  - sadtalker/sadtalker.pth: {'‚úì' if (MODEL_ROOT/'sadtalker'/'sadtalker.pth').exists() else '‚úó'}\")\n    print(f\"  - wav2lip/wav2lip_gan.pth: {'‚úì' if (MODEL_ROOT/'wav2lip'/'wav2lip_gan.pth').exists() else '‚úó'}\")\n    print(\"\\nPlease run: make download-models\")\nelse:\n    # Use preset avatar if available\n    if 'avatar_files' in globals() and 'creator' in avatar_files:\n        face_image = avatar_files['creator']\n        print(f\"Using frontend preset avatar: {face_image}\\n\")\n    else:\n        face_image = str(test_image)\n        print(f\"Using test asset: {face_image}\\n\")\n    \n    start_time = time.time()\n    \n    try:\n        result = render_pipeline(\n            face_image=face_image,\n            audio=str(test_audio),\n            out_path=str(realtime_video),\n            quality_mode=\"real_time\"  # Fast processing for streaming\n        )\n        \n        processing_time = time.time() - start_time\n        \n        print(f\"\\n‚è±Ô∏è  Processing time: {processing_time:.2f} seconds\")\n        display_video(result, \"Real-Time Avatar (Live Streaming Ready)\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error: {e}\")\n        print(f\"\\nMODEL_ROOT: {MODEL_ROOT}\")\n        print(f\"EXT_DEPS_DIR: {EXT_DEPS_DIR}\")\n        print(\"\\nTroubleshooting:\")\n        print(\"1. Ensure models are downloaded: make download-models\")\n        print(\"2. Install external deps: make install-git-deps\")\n        print(\"3. Check that external_deps/ contains SadTalker and Wav2Lip\")"
  },
  {
   "cell_type": "markdown",
   "id": "section-comparison",
   "metadata": {},
   "source": [
    "## 6. Quality Mode Comparison\n",
    "\n",
    "Let's compare the two quality modes:\n",
    "\n",
    "| Feature | Real-Time | High-Quality |\n",
    "|---------|-----------|-------------|\n",
    "| **Speed** | <3s | ~10-30s |\n",
    "| **GPU Required** | No | Yes |\n",
    "| **Bitrate** | 2 Mbps | 6 Mbps |\n",
    "| **Enhancement** | None | GFPGAN |\n",
    "| **Best For** | Live streaming | Pre-recorded content |\n",
    "| **Pipeline** | SadTalker + Wav2Lip | FOMM + Diff2Lip + GFPGAN |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-custom-content",
   "metadata": {},
   "source": [
    "## 7. Create Your Own Content\n",
    "\n",
    "Ready to create your own avatar videos? Here's a template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-content-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for creating your own avatar videos\n",
    "\n",
    "def create_custom_avatar(\n",
    "    image_path: str,\n",
    "    audio_path: str,\n",
    "    output_name: str,\n",
    "    quality: str = \"auto\",\n",
    "    description: str = \"Custom Avatar\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a custom avatar video\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to avatar image (PNG/JPG)\n",
    "        audio_path: Path to audio file (WAV/MP3)\n",
    "        output_name: Name for output video (without extension)\n",
    "        quality: 'real_time', 'high_quality', or 'auto'\n",
    "        description: Description for display\n",
    "    \"\"\"\n",
    "    output_path = output_dir / f\"{output_name}.mp4\"\n",
    "    \n",
    "    print(f\"üé¨ Creating {description}...\")\n",
    "    print(f\"   Image: {image_path}\")\n",
    "    print(f\"   Audio: {audio_path}\")\n",
    "    print(f\"   Quality: {quality}\\n\")\n",
    "    \n",
    "    try:\n",
    "        result = render_pipeline(\n",
    "            face_image=image_path,\n",
    "            audio=audio_path,\n",
    "            out_path=str(output_path),\n",
    "            quality_mode=quality\n",
    "        )\n",
    "        display_video(result, description)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úì Custom avatar function ready!\")\n",
    "print(\"\\nUsage example:\")\n",
    "print('create_custom_avatar(')\n",
    "print('    image_path=\"path/to/your/image.png\",')\n",
    "print('    audio_path=\"path/to/your/audio.wav\",')\n",
    "print('    output_name=\"my_avatar\",')\n",
    "print('    quality=\"high_quality\",')\n",
    "print('    description=\"My Custom Avatar\"')\n",
    "print(')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create your own avatar\n",
    "# Uncomment and modify the paths below:\n",
    "\n",
    "# create_custom_avatar(\n",
    "#     image_path=\"path/to/your/image.png\",\n",
    "#     audio_path=\"path/to/your/audio.wav\",\n",
    "#     output_name=\"my_first_avatar\",\n",
    "#     quality=\"auto\",\n",
    "#     description=\"My First Custom Avatar\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-tips",
   "metadata": {},
   "source": [
    "## 8. Tips for Creating Great Demo Videos\n",
    "\n",
    "### üñºÔ∏è Image Requirements\n",
    "- **Format**: PNG or JPG\n",
    "- **Face**: Clear, front-facing portrait\n",
    "- **Resolution**: Minimum 512x512, recommended 1024x1024\n",
    "- **Lighting**: Well-lit, avoid harsh shadows\n",
    "- **Background**: Clean, uncluttered\n",
    "\n",
    "### üé§ Audio Requirements\n",
    "- **Format**: WAV or MP3\n",
    "- **Sample Rate**: 16kHz recommended\n",
    "- **Quality**: Clear speech, minimal background noise\n",
    "- **Length**: Keep it concise (10-30 seconds for demos)\n",
    "\n",
    "### üé¨ Demo Video Best Practices\n",
    "1. **Keep it short**: 5-15 seconds for website demos\n",
    "2. **Clear message**: Focus on one key benefit\n",
    "3. **Professional appearance**: Use high-quality mode for marketing\n",
    "4. **Multiple variations**: Create videos for different use cases\n",
    "5. **Test on different devices**: Ensure compatibility\n",
    "\n",
    "### üìä Recommended Demo Topics\n",
    "1. **Customer Support**: \"Hello! I'm here to help you 24/7\"\n",
    "2. **AI Teacher**: \"Welcome to today's lesson on...\"\n",
    "3. **Brand Ambassador**: \"Discover our latest product...\"\n",
    "4. **Game NPC**: \"Greetings, traveler! What brings you here?\"\n",
    "5. **News Anchor**: \"Good evening, here are today's top stories...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-batch",
   "metadata": {},
   "source": [
    "## 9. Batch Processing (Multiple Videos)\n",
    "\n",
    "Create multiple demo videos at once for your website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_create_demos(demos_config):\n",
    "    \"\"\"\n",
    "    Create multiple demo videos from a configuration list\n",
    "    \n",
    "    Args:\n",
    "        demos_config: List of dictionaries with demo configurations\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"üé¨ Starting batch creation of {len(demos_config)} videos...\\n\")\n",
    "    \n",
    "    for i, config in enumerate(demos_config, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing {i}/{len(demos_config)}: {config['name']}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        result = create_custom_avatar(\n",
    "            image_path=config['image'],\n",
    "            audio_path=config['audio'],\n",
    "            output_name=config['output'],\n",
    "            quality=config.get('quality', 'auto'),\n",
    "            description=config['name']\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'name': config['name'],\n",
    "            'output': result,\n",
    "            'success': result is not None\n",
    "        })\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(\"üìä BATCH PROCESSING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    print(f\"‚úÖ Successful: {successful}/{len(results)}\")\n",
    "    \n",
    "    if successful < len(results):\n",
    "        print(f\"‚ùå Failed: {len(results) - successful}\")\n",
    "        print(\"\\nFailed videos:\")\n",
    "        for r in results:\n",
    "            if not r['success']:\n",
    "                print(f\"  - {r['name']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example configuration for multiple demos\n",
    "demo_configs = [\n",
    "    {\n",
    "        'name': 'Hello World Demo',\n",
    "        'image': str(test_image),\n",
    "        'audio': str(test_audio),\n",
    "        'output': 'demo_1_hello',\n",
    "        'quality': 'auto'\n",
    "    },\n",
    "    # Add more demos here:\n",
    "    # {\n",
    "    #     'name': 'Customer Support Demo',\n",
    "    #     'image': 'assets/support_avatar.png',\n",
    "    #     'audio': 'assets/support_script.wav',\n",
    "    #     'output': 'demo_2_support',\n",
    "    #     'quality': 'high_quality'\n",
    "    # },\n",
    "]\n",
    "\n",
    "# Uncomment to run batch processing:\n",
    "# results = batch_create_demos(demo_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fl5fqpa0o9s",
   "source": "### 9.1 Render All Frontend Preset Avatars\n\nCreate videos for all downloaded frontend avatar presets (matching the website).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "nkzz2jpetkt",
   "source": "# Render ALL frontend preset avatars\n# Uncomment to execute batch rendering\n\n# from pathlib import Path\n#\n# if 'avatar_files' in globals() and avatar_files:\n#     print(f\"üé¨ Batch rendering {len(avatar_files)} frontend preset avatars...\\n\")\n#     \n#     outputs = {}\n#     for preset_id, face_image in avatar_files.items():\n#         out_path = output_dir / f\"preset_{preset_id}.mp4\"\n#         \n#         print(f\"\\n{'='*60}\")\n#         print(f\"Rendering preset: {preset_id}\")\n#         print(f\"{'='*60}\")\n#         \n#         try:\n#             result = render_pipeline(\n#                 face_image=face_image,\n#                 audio=str(test_audio),\n#                 out_path=str(out_path),\n#                 quality_mode=\"auto\",  # Auto-select based on available models\n#             )\n#             outputs[preset_id] = result\n#             print(f\"‚úì Success: {result}\")\n#         except Exception as e:\n#             print(f\"‚úó Failed: {e}\")\n#             outputs[preset_id] = None\n#     \n#     # Summary\n#     print(f\"\\n\\n{'='*60}\")\n#     print(\"üìä BATCH RENDERING SUMMARY\")\n#     print(f\"{'='*60}\")\n#     \n#     successful = sum(1 for v in outputs.values() if v is not None)\n#     print(f\"\\n‚úÖ Successful: {successful}/{len(outputs)}\")\n#     \n#     if successful < len(outputs):\n#         print(f\"‚ùå Failed: {len(outputs) - successful}\")\n#         print(\"\\nFailed presets:\")\n#         for k, v in outputs.items():\n#             if v is None:\n#                 print(f\"  - {k}\")\n#     \n#     print(f\"\\nOutput files in: {output_dir}/\")\n# else:\n#     print(\"‚ö†Ô∏è No avatar presets available. Run the avatar download cell first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "section-api-reference",
   "metadata": {},
   "source": [
    "## 10. API Reference\n",
    "\n",
    "### Core Function: `render_pipeline()`\n",
    "\n",
    "```python\n",
    "render_pipeline(\n",
    "    face_image: str,           # Path to avatar image (PNG/JPG)\n",
    "    audio: str,                # Path to audio file (WAV/MP3)\n",
    "    out_path: str,             # Output video path\n",
    "    reference_video: str = None,  # Optional driving video\n",
    "    quality_mode: str = \"auto\"    # \"real_time\", \"high_quality\", or \"auto\"\n",
    ") -> str  # Returns absolute path to generated video\n",
    "```\n",
    "\n",
    "### Quality Modes\n",
    "\n",
    "#### `real_time`\n",
    "- **Speed**: <3 seconds latency\n",
    "- **Pipeline**: SadTalker + Wav2Lip\n",
    "- **GPU**: Optional (CPU fallback available)\n",
    "- **Use cases**: Live streaming, chatbots, real-time interactions\n",
    "\n",
    "#### `high_quality`\n",
    "- **Quality**: Maximum with GFPGAN enhancement\n",
    "- **Pipeline**: FOMM + Diff2Lip + GFPGAN\n",
    "- **GPU**: Required (V100 or better recommended)\n",
    "- **Use cases**: YouTube content, marketing videos, professional productions\n",
    "\n",
    "#### `auto` (default)\n",
    "- Automatically selects the best mode based on:\n",
    "  - GPU availability\n",
    "  - Model checkpoint availability\n",
    "  - System resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-next-steps",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "### üìö Learn More\n",
    "- Read the full documentation: [README.md](README.md)\n",
    "- Explore quality modes: [docs/QUALITY_MODES.md](docs/QUALITY_MODES.md)\n",
    "- Check out the API: Start the FastAPI server with `make run`\n",
    "\n",
    "### üöÄ Deploy to Production\n",
    "1. **Docker**: `make docker-build && make docker-run`\n",
    "2. **Kubernetes**: `helm install avatar-renderer ./charts/avatar-renderer`\n",
    "3. **Frontend**: Deploy the Next.js app from `/frontend` to Vercel\n",
    "\n",
    "### üé® Create More Content\n",
    "1. Prepare your avatar images and scripts\n",
    "2. Use this notebook to generate demo videos\n",
    "3. Upload to your website at [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "\n",
    "### üí° Advanced Features\n",
    "- **MCP Integration**: Use the STDIO server for AI agent communication\n",
    "- **REST API**: Integrate with your applications via FastAPI\n",
    "- **Custom Models**: Fine-tune models for your specific use case\n",
    "- **Batch Processing**: Process multiple videos efficiently\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully created your first AI-powered talking avatar!\n",
    "\n",
    "**Need help?** Check out:\n",
    "- üåê Website: [https://avatar-renderer-mcp.vercel.app/](https://avatar-renderer-mcp.vercel.app/)\n",
    "- üì¶ Repository: [https://github.com/ruslanmv/avatar-renderer-mcp](https://github.com/ruslanmv/avatar-renderer-mcp)\n",
    "- üìß Contact: contact@ruslanmv.com\n",
    "- üåü Author: [Ruslan Magana Vsevolodovna](https://ruslanmv.com)\n",
    "\n",
    "---\n",
    "\n",
    "*Transform static images into dynamic, AI-powered avatars with realistic expressions and voice synchronization*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}